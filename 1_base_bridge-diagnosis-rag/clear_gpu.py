import torch
import gc

print("ğŸ§¹ GPUãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢ä¸­...")

# GPUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
if torch.cuda.is_available():
    print(f"ã‚¯ãƒªã‚¢å‰: {torch.cuda.memory_allocated() / 1024**3:.2f} GB allocated")
    print(f"         {torch.cuda.memory_reserved() / 1024**3:.2f} GB reserved")
    
    # å…¨ã¦ã®GPUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    gc.collect()
    
    print(f"ã‚¯ãƒªã‚¢å¾Œ: {torch.cuda.memory_allocated() / 1024**3:.2f} GB allocated")
    print(f"         {torch.cuda.memory_reserved() / 1024**3:.2f} GB reserved")
    print("âœ… GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢å®Œäº†")
else:
    print("âŒ CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
