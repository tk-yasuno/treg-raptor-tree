# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ å‰ææ¡ä»¶

- Python 3.10ä»¥ä¸Š
- CUDAå¯¾å¿œGPUï¼ˆæ¨å¥¨ï¼š8GBä»¥ä¸Šã®VRAMï¼‰
- Ollamaï¼ˆLLMç”¨ï¼‰

---

## ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1: Pythonç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### Option A: Pipenvï¼ˆæ¨å¥¨ï¼‰

```bash
cd C:\Users\yasun\LangChain\learning-langchain\multimd-raptor-colvbert-blip2

# ä»®æƒ³ç’°å¢ƒä½œæˆã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pipenv install

# ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
pipenv shell
```

### Option B: venv + pip

```bash
cd C:\Users\yasun\LangChain\learning-langchain\multimd-raptor-colvbert-blip2

# ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv venv

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆï¼ˆWindowsï¼‰
.\venv\Scripts\Activate.ps1

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

---

## ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—2: Ollamaã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 2.1 Ollamaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# Ollamaã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# https://ollama.ai/

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
ollama --version
```

### 2.2 LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```bash
# gpt-oss:20b ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆç´„12GBï¼‰
ollama pull gpt-oss:20b

# ãƒ¢ãƒ‡ãƒ«ç¢ºèª
ollama list
```

### 2.3 Ollamaã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•

```bash
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•
ollama serve

# ã¾ãŸã¯ã€åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§èµ·å‹•
Start-Process powershell -ArgumentList "-NoExit", "-Command", "ollama serve"
```

### 2.4 å‹•ä½œç¢ºèª

```bash
# ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
curl http://localhost:11434/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Hello",
  "stream": false
}'
```

---

## ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—3: MeCabã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæ—¥æœ¬èªå½¢æ…‹ç´ è§£æï¼‰

### Windows

```bash
# MeCabã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# https://github.com/ikegami-yukino/mecab/releases

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
$env:MECAB_PATH = "C:\Program Files (x86)\MeCab\bin"
```

### ç¢ºèª

```python
import MeCab
tagger = MeCab.Tagger()
print(tagger.parse("æ©‹æ¢è¨ºæ–­"))
# å‡ºåŠ›: æ©‹æ¢	åè©,ä¸€èˆ¬,*,*,*,*,æ©‹æ¢,ã‚­ãƒ§ã‚¦ãƒªãƒ§ã‚¦,ã‚­ãƒ§ãƒ¼ãƒªãƒ§ãƒ¼
```

---

## ğŸ” ã‚¹ãƒ†ãƒƒãƒ—4: å‹•ä½œç¢ºèª

### 4.1 ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª

```bash
# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
ls data\doken_bridge_diagnosis_logic\images | Measure-Object
# æœŸå¾…å€¤: 2400+ãƒ•ã‚¡ã‚¤ãƒ«

# PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
ls data\doken_bridge_diagnosis_logic\*.pdf | Measure-Object
# æœŸå¾…å€¤: 46ãƒ•ã‚¡ã‚¤ãƒ«

# ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç¢ºèª
Test-Path data\doken_bridge_diagnosis_logic\pdf_text_cache.json
# æœŸå¾…å€¤: True
```

### 4.2 ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œãƒ†ã‚¹ãƒˆ

```bash
# èªå½™è¾æ›¸ã®ãƒ†ã‚¹ãƒˆ
python -c "from bridge_diagnosis_vocab import BRIDGE_TRANSLATION_DICT; print(len(BRIDGE_TRANSLATION_DICT), 'èªå½™ç™»éŒ²æ¸ˆã¿')"

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
python -c "from visual_raptor_colbert_bridge import BridgeRAPTORColBERT; print('âœ… Import successful')"
```

---

## ğŸš€ ã‚¹ãƒ†ãƒƒãƒ—5: åˆå›å®Ÿè¡Œ

### 5.1 å°è¦æ¨¡ãƒ†ã‚¹ãƒˆï¼ˆ250ãƒãƒ£ãƒ³ã‚¯ï¼‰

```python
# scaling_test_raptor.py ã‚’ç·¨é›†
sample_sizes = [250]  # 250ãƒãƒ£ãƒ³ã‚¯ã§ãƒ†ã‚¹ãƒˆ
```

```bash
# å®Ÿè¡Œï¼ˆç´„5-10åˆ†ï¼‰
python scaling_test_raptor.py
```

### 5.2 çµæœã®ç¢ºèª

```bash
# ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
ls data\doken_bridge_diagnosis_logic\results\

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# - scaling_test_tree_250chunks_*.pkl
# - scaling_test_log_250chunks_*.txt
# - scaling_test_*.json
# - scaling_test_graph_*.png
```

### 5.3 å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆ

```bash
# ãƒ„ãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèª
$treefile = (Get-ChildItem data\doken_bridge_diagnosis_logic\results\scaling_test_tree_250chunks_*.pkl | Select-Object -First 1).FullName

# å¯è¦–åŒ–å®Ÿè¡Œ
python visualize_bridge_tree.py --tree_file $treefile --max_depth 3
```

---

## ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—6: æœ¬ç•ªå®Ÿè¡Œï¼ˆ1600ãƒãƒ£ãƒ³ã‚¯ï¼‰

```python
# scaling_test_raptor.py ã‚’ç·¨é›†
sample_sizes = [1600]  # 1600ãƒãƒ£ãƒ³ã‚¯
```

```bash
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼ˆ60-90åˆ†ï¼‰
Start-Process powershell -ArgumentList "-NoExit", "-Command", `
  "[Console]::OutputEncoding = [System.Text.Encoding]::UTF8; python scaling_test_raptor.py 2>&1 | Tee-Object -FilePath 'build_1600chunks.log'" `
  -WindowStyle Minimized

# é€²æ—ç¢ºèªï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
Get-Content build_1600chunks.log -Tail 30 -Wait
```

---

## âš ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### GPU ãƒ¡ãƒ¢ãƒªä¸è¶³

```python
# scaling_test_raptor.py ã§ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
encode_kwargs={'normalize_embeddings': True, 'batch_size': 32}  # 64 â†’ 32
```

### Ollamaæ¥ç¶šã‚¨ãƒ©ãƒ¼

```bash
# OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
curl http://localhost:11434/api/ps

# å†èµ·å‹•
taskkill /F /IM ollama.exe
ollama serve
```

### MeCab ã‚¨ãƒ©ãƒ¼

```bash
# ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèª
echo $env:MECAB_PATH

# ãƒ‘ã‚¹ã‚’è¨­å®š
$env:MECAB_PATH = "C:\Program Files (x86)\MeCab\bin"
```

### æ—¥æœ¬èªå‡ºåŠ›ã®æ–‡å­—åŒ–ã‘

```python
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†’é ­ã«è¿½åŠ 
import sys, io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
```

---

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒè§£æ±ºã—ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

1. **README_Bridge.md**: è©³ç´°ãªæŠ€è¡“ä»•æ§˜
2. **Bridge_Practice.md**: å®Ÿè£…ã®æ•™è¨“ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
3. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: `data/doken_bridge_diagnosis_logic/results/scaling_test_log_*.txt`

---

**ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼ğŸ‰**
