"""
ColModernVBERT (SigLIP) vs ColVBERT (BLIP) å¤§è¦æ¨¡æ€§èƒ½æ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ
RAPTOR Treeæ§‹ç¯‰ã‚’å«ã‚€åŒ…æ‹¬çš„è©•ä¾¡ - 46 PDFæ–‡æ›¸ç‰ˆï¼ˆãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ç‰ˆï¼‰

æ—¢å­˜ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦:
1. ãƒ†ã‚­ã‚¹ãƒˆã‚’500ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
2. å…¨ãƒãƒ£ãƒ³ã‚¯ã§RAPTORéšå±¤ãƒ„ãƒªãƒ¼ã‚’æ§‹ç¯‰
3. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼æ€§èƒ½ã‚’æ¯”è¼ƒ
4. GPUä½¿ç”¨é‡ã¨Treeæ§‹é€ ã‚’è©•ä¾¡
"""

import os
import sys
import time
import json
import torch
import numpy as np
from datetime import datetime
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib
from glob import glob
import subprocess

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from visual_raptor_colbert import VisualRAPTORColBERT, VisualDocument

print("=" * 80)
print("ColModernVBERT (SigLIP) vs ColVBERT (BLIP) å¤§è¦æ¨¡æ€§èƒ½æ¯”è¼ƒ")
print("RAPTOR Treeæ§‹ç¯‰ + éšå±¤çš„æ¤œç´¢è©•ä¾¡ï¼ˆãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ç‰ˆï¼‰")
print("å®Ÿéš›ã®PDFãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ (46æ–‡æ›¸ã€2378ãƒšãƒ¼ã‚¸ â†’ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²)")
print("=" * 80)

# GPUæƒ…å ±å–å¾—é–¢æ•°
def get_gpu_memory_usage():
    """nvidia-smiã‚’ä½¿ç”¨ã—ã¦GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu', 
             '--format=csv,noheader,nounits'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if lines:
                values = lines[0].split(',')
                return {
                    'memory_used_mb': float(values[0].strip()),
                    'memory_total_mb': float(values[1].strip()),
                    'gpu_utilization': float(values[2].strip())
                }
    except Exception as e:
        print(f"  âš ï¸ GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    return {'memory_used_mb': 0, 'memory_total_mb': 0, 'gpu_utilization': 0}

def count_tree_nodes(tree):
    """ãƒ„ãƒªãƒ¼ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—"""
    if not tree or not isinstance(tree, dict):
        return {'num_leaf_nodes': 0, 'num_internal_nodes': 0, 'total_nodes': 0, 'max_depth': 0}
    
    def count_recursive(node, depth=0):
        """å†å¸°çš„ã«ãƒãƒ¼ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ (leaf_count, internal_count, max_depth)"""
        if not node or not isinstance(node, dict):
            return (0, 0, depth)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãŒãªã„å ´åˆã¯ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰
        clusters = node.get('clusters', {})
        if not clusters:
            return (1, 0, depth)
        
        # å†…éƒ¨ãƒãƒ¼ãƒ‰ã¨ã—ã¦1ã¤ã‚«ã‚¦ãƒ³ãƒˆ
        total_leaf = 0
        total_internal = 1  # ã“ã®ãƒãƒ¼ãƒ‰è‡ªä½“
        max_child_depth = depth
        
        # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®å­ãƒãƒ¼ãƒ‰ã‚’å†å¸°çš„ã«ã‚«ã‚¦ãƒ³ãƒˆ
        for cluster_id, cluster_data in clusters.items():
            if isinstance(cluster_data, dict) and 'children' in cluster_data:
                leaf, internal, child_depth = count_recursive(cluster_data['children'], depth + 1)
                total_leaf += leaf
                total_internal += internal
                max_child_depth = max(max_child_depth, child_depth)
        
        return (total_leaf, total_internal, max_child_depth)
    
    leaf_count, internal_count, max_depth = count_recursive(tree, 0)
    
    return {
        'num_leaf_nodes': leaf_count,
        'num_internal_nodes': internal_count,
        'total_nodes': leaf_count + internal_count,
        'max_depth': max_depth
    }

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 1/10] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™...")
output_dir = Path("data/encoder_comparison_46pdfs")
results_dir = output_dir / "results"
trees_dir = output_dir / "raptor_trees"
images_dir = output_dir / "images"

for dir_path in [results_dir, trees_dir]:
    dir_path.mkdir(parents=True, exist_ok=True)
    print(f"âœ… {dir_path} æº–å‚™å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—2: æ—¢å­˜ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 2/10] æ—¢å­˜ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿ä¸­...")

if not images_dir.exists():
    print(f"âŒ ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {images_dir}")
    sys.exit(1)

image_files = sorted(glob(str(images_dir / "*.png")))
print(f"âœ… {len(image_files)}æšã®ç”»åƒã‚’ç™ºè¦‹")

# ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿
cache_file = output_dir / "pdf_text_cache.json"
pdf_text_cache = {}
if cache_file.exists():
    with open(cache_file, 'r', encoding='utf-8') as f:
        pdf_text_cache = json.load(f)
    print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿: {len(pdf_text_cache)}ã‚¨ãƒ³ãƒˆãƒª")
else:
    print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {cache_file}")

# ã‚¹ãƒ†ãƒƒãƒ—3: VisualDocumentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¦ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
print(f"\n[ã‚¹ãƒ†ãƒƒãƒ— 3/10] {len(image_files)}å€‹ã®VisualDocumentã‚’ä½œæˆã—ã¦ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ä¸­...")

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å™¨ã®è¨­å®š
CHUNK_SIZE = 800
CHUNK_OVERLAP = 150

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=CHUNK_SIZE,
    chunk_overlap=CHUNK_OVERLAP,
    length_function=len,
)

visual_documents = []
total_chunks = 0

for img_path in image_files:
    img_path_obj = Path(img_path)
    cached_text = pdf_text_cache.get(str(img_path_obj), "")
    
    # ãƒ†ã‚­ã‚¹ãƒˆãŒååˆ†ã«ã‚ã‚‹å ´åˆã¯ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    if cached_text and len(cached_text.strip()) > 100:
        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
        chunks = text_splitter.split_text(cached_text)
        
        for chunk_idx, chunk_text in enumerate(chunks):
            # å„ãƒãƒ£ãƒ³ã‚¯ã‚’VisualDocumentã¨ã—ã¦ä¿å­˜
            doc = VisualDocument(
                image_path=str(img_path_obj),
                metadata={
                    'source': img_path_obj.stem,
                    'page_number': img_path_obj.stem.split('_page')[-1].replace('.png', '') if '_page' in img_path_obj.stem else '1',
                    'chunk_index': chunk_idx,
                    'total_chunks': len(chunks)
                }
            )
            doc.cached_text = chunk_text
            visual_documents.append(doc)
        
        total_chunks += len(chunks)
    else:
        # ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã„å ´åˆã¯ãã®ã¾ã¾1ã¤ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
        doc = VisualDocument(
            image_path=str(img_path_obj),
            metadata={
                'source': img_path_obj.stem,
                'page_number': img_path_obj.stem.split('_page')[-1].replace('.png', '') if '_page' in img_path_obj.stem else '1',
                'chunk_index': 0,
                'total_chunks': 1
            }
        )
        doc.cached_text = cached_text if cached_text else ""
        visual_documents.append(doc)
        total_chunks += 1

print(f"âœ… {len(image_files)}ãƒšãƒ¼ã‚¸ã‹ã‚‰{len(visual_documents)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆå®Œäº†")
print(f"   å¹³å‡ãƒãƒ£ãƒ³ã‚¯æ•°/ãƒšãƒ¼ã‚¸: {len(visual_documents)/len(image_files):.1f}")

# ã‚¹ãƒ†ãƒƒãƒ—4: æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 4/10] æ¤œç´¢ã‚¯ã‚¨ãƒªã¨é–¢é€£æ€§åˆ¤å®šãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")

queries = [
    {
        'query_id': 'Q1',
        'query': 'æ´¥æ³¢è­¦å ±ã®ç™ºä»¤çŠ¶æ³ã¨é¿é›£æŒ‡ç¤ºã«ã¤ã„ã¦',
        'relevant_docs': []
    },
    {
        'query_id': 'Q2',
        'query': 'é¿é›£æ‰€ã®é‹å–¶ã¨ç‰©è³‡é…å¸ƒã®æ–¹æ³•',
        'relevant_docs': []
    },
    {
        'query_id': 'Q3',
        'query': 'ç½å®³æ™‚ã®é€šä¿¡æ‰‹æ®µã¨æƒ…å ±ä¼é”',
        'relevant_docs': []
    },
    {
        'query_id': 'Q4',
        'query': 'å¾©æ—§ãƒ»å¾©èˆˆè¨ˆç”»ã®ç­–å®šãƒ—ãƒ­ã‚»ã‚¹',
        'relevant_docs': []
    },
    {
        'query_id': 'Q5',
        'query': 'ãƒœãƒ©ãƒ³ãƒ†ã‚£ã‚¢æ´»å‹•ã®èª¿æ•´ã¨æ”¯æ´',
        'relevant_docs': []
    }
]

print(f"âœ… {len(queries)}å€‹ã®ã‚¯ã‚¨ãƒªç”Ÿæˆå®Œäº†")

print("\n" + "=" * 80)
print("ColVBERT (BLIP) ã§RAPTOR Treeæ§‹ç¯‰ + è©•ä¾¡")
print("=" * 80)

# ã‚¹ãƒ†ãƒƒãƒ—5: ColVBERT (BLIP) ã§RAPTOR Treeæ§‹ç¯‰
print(f"\n[ã‚¹ãƒ†ãƒƒãƒ— 5/10] ColVBERT (BLIP) ã§RAPTOR Treeæ§‹ç¯‰ä¸­...")
print(f"  å¯¾è±¡ãƒãƒ£ãƒ³ã‚¯æ•°: {len(visual_documents)}")

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import ChatOllama

# GPUä¸¦åˆ—å‡¦ç†ã§ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ï¼ˆOllamaã‚ˆã‚ŠHTTPé€šä¿¡ã‚’å›é¿ã—ã¦é«˜é€ŸåŒ–ï¼‰
import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"  Using device for text embeddings: {device}")

embeddings_model = HuggingFaceEmbeddings(
    model_name="mixedbread-ai/mxbai-embed-large-v1",
    model_kwargs={'device': device},
    encode_kwargs={'normalize_embeddings': True, 'batch_size': 64}
)

# æ—¥æœ¬èªå¯¾å¿œã®æ±ç”¨LLMã‚’ä½¿ç”¨ï¼ˆè¦ç´„ã‚¿ã‚¹ã‚¯ã«é©ã—ã¦ã„ã‚‹ï¼‰
llm = ChatOllama(
    model="qwen2.5:7b",  # granite-code:8b â†’ qwen2.5:7b (æ—¥æœ¬èªå¯¾å¿œã€æ±ç”¨ã‚¿ã‚¹ã‚¯å‘ã‘)
    base_url="http://localhost:11434",
    temperature=0.3,  # 0.0 â†’ 0.3 (ã‚„ã‚„å‰µé€ çš„ãªè¦ç´„ã‚’å¯èƒ½ã«ã™ã‚‹)
    num_ctx=8192  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æ˜ç¤ºçš„ã«è¨­å®š
)

colbert_config = {
    'encoder_type': 'colbert',
    'text_model': 'intfloat/multilingual-e5-large',  # Vision encoderãŒä½¿ç”¨ã™ã‚‹HuggingFaceãƒ¢ãƒ‡ãƒ«
    'vision_model': 'Salesforce/blip-image-captioning-base',
    'embedding_dim': 768,
    'use_cross_attention': False
}

pdf_source_dir = Path("data/disaster_visual_documents")

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆé–‹å§‹å‰ï¼‰
gpu_before_colbert = get_gpu_memory_usage()
print(f"GPUçŠ¶æ…‹ (é–‹å§‹å‰): {gpu_before_colbert['memory_used_mb']:.0f}MB / {gpu_before_colbert['memory_total_mb']:.0f}MB")

colbert_system = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=False,
    colbert_config=colbert_config,
    pdf_source_dir=str(pdf_source_dir)
)

print("ColVBERTåˆæœŸåŒ–å®Œäº† - RAPTOR Treeæ§‹ç¯‰é–‹å§‹...")

# RAPTOR Treeã‚’æ§‹ç¯‰ã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿
colbert_tree = None
colbert_tree_build_time = 0
colbert_tree_stats = {'num_leaf_nodes': 0, 'num_internal_nodes': 0, 'total_nodes': 0, 'max_depth': 0}
colbert_tree_pickle = trees_dir / "colbert_blip_tree_46pdfs_chunked.pkl"

if colbert_tree_pickle.exists():
    print(f"ğŸ“‚ æ—¢å­˜ã®ColVBERT Treeã‚’èª­ã¿è¾¼ã¿ä¸­: {colbert_tree_pickle}")
    try:
        import pickle
        with open(colbert_tree_pickle, 'rb') as f:
            tree_data = pickle.load(f)
            colbert_tree = tree_data['tree']
            colbert_tree_build_time = tree_data['build_time']
            colbert_tree_stats = tree_data['stats']
        print(f"âœ… ColVBERT Treeèª­ã¿è¾¼ã¿å®Œäº†")
        print(f"  æ§‹ç¯‰æ™‚é–“ (å‰å›): {colbert_tree_build_time:.2f}ç§’ ({colbert_tree_build_time/60:.1f}åˆ†)")
        print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {colbert_tree_stats['total_nodes']}")
        print(f"  ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {colbert_tree_stats['num_leaf_nodes']}")
        print(f"  å†…éƒ¨ãƒãƒ¼ãƒ‰: {colbert_tree_stats['num_internal_nodes']}")
        print(f"  æœ€å¤§æ·±åº¦: {colbert_tree_stats['max_depth']}")
        # Treeã‚’ã‚·ã‚¹ãƒ†ãƒ ã«è¨­å®š
        colbert_system.tree = colbert_tree
    except Exception as e:
        print(f"âš ï¸ Treeèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print("æ–°è¦ã«Treeã‚’æ§‹ç¯‰ã—ã¾ã™...")
        colbert_tree = None

if colbert_tree is None:
    print("ğŸŒ³ æ–°è¦ã«RAPTOR Treeã‚’æ§‹ç¯‰ä¸­...")
    colbert_tree_start_time = time.time()
    colbert_gpu_during_tree = []

    try:
        colbert_tree = colbert_system.build_tree(visual_documents)
        
        # å®šæœŸçš„ã«GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²
        for i in range(5):
            time.sleep(0.5)
            colbert_gpu_during_tree.append(get_gpu_memory_usage())
        
        colbert_tree_build_time = time.time() - colbert_tree_start_time
        
        # ãƒ„ãƒªãƒ¼çµ±è¨ˆã‚’å–å¾—
        colbert_tree_stats = count_tree_nodes(colbert_tree)
        
        print(f"âœ… ColVBERT RAPTOR Treeæ§‹ç¯‰å®Œäº†")
        print(f"  æ§‹ç¯‰æ™‚é–“: {colbert_tree_build_time:.2f}ç§’ ({colbert_tree_build_time/60:.1f}åˆ†)")
        print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {colbert_tree_stats['total_nodes']}")
        print(f"  ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {colbert_tree_stats['num_leaf_nodes']}")
        print(f"  å†…éƒ¨ãƒãƒ¼ãƒ‰: {colbert_tree_stats['num_internal_nodes']}")
        print(f"  æœ€å¤§æ·±åº¦: {colbert_tree_stats['max_depth']}")
        
        # ãƒ„ãƒªãƒ¼ã‚’pickleã¨ã—ã¦ä¿å­˜
        try:
            import pickle
            with open(colbert_tree_pickle, 'wb') as f:
                pickle.dump({
                    'tree': colbert_tree,
                    'build_time': colbert_tree_build_time,
                    'stats': colbert_tree_stats
                }, f)
            print(f"  ãƒ„ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {colbert_tree_pickle}")
        except Exception as e:
            print(f"  âš ï¸ ãƒ„ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ„ãƒªãƒ¼çµ±è¨ˆã‚’JSONã¨ã—ã¦ä¿å­˜
        try:
            colbert_tree_file = trees_dir / "colbert_blip_tree_46pdfs_chunked.json"
            with open(colbert_tree_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'build_time': colbert_tree_build_time,
                    'stats': colbert_tree_stats,
                    'num_chunks': len(visual_documents),
                    'num_pages': len(image_files),
                    'chunk_size': CHUNK_SIZE,
                    'chunk_overlap': CHUNK_OVERLAP,
                    'note': 'Tree structure saved (Document objects not serializable)'
                }, f, indent=2, ensure_ascii=False)
            print(f"  ãƒ„ãƒªãƒ¼çµ±è¨ˆä¿å­˜: {colbert_tree_file}")
        except Exception as e:
            print(f"  âš ï¸ ãƒ„ãƒªãƒ¼çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
    except Exception as e:
        print(f"âŒ ColVBERT RAPTOR Treeæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
else:
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å ´åˆã¯GPUæ¸¬å®šã‚’ã‚¹ã‚­ãƒƒãƒ—
    colbert_gpu_during_tree = []

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆå®Œäº†å¾Œï¼‰
gpu_after_colbert_tree = get_gpu_memory_usage()
colbert_tree_gpu_peak = max([g['memory_used_mb'] for g in colbert_gpu_during_tree]) if colbert_gpu_during_tree else gpu_after_colbert_tree['memory_used_mb']

# ã‚¹ãƒ†ãƒƒãƒ—6: ColVBERT (BLIP) ã§éšå±¤çš„æ¤œç´¢è©•ä¾¡
print(f"\n[ã‚¹ãƒ†ãƒƒãƒ— 6/10] ColVBERT (BLIP) ã§éšå±¤çš„æ¤œç´¢è©•ä¾¡ä¸­...")

colbert_search_times = []
colbert_search_results = []

if colbert_tree:
    for query in queries:
        search_start = time.perf_counter()
        try:
            # éšå±¤çš„æ¤œç´¢å®Ÿè¡Œ
            results = colbert_system.retrieve(
                query['query'],
                tree_traversal='collapsed',
                top_k=10
            )
            search_time = time.perf_counter() - search_start
            colbert_search_times.append(search_time)
            colbert_search_results.append(results)
            
            print(f"  ã‚¯ã‚¨ãƒª '{query['query_id']}': {search_time*1000:.2f}ms, {len(results)}ä»¶å–å¾—")
        except Exception as e:
            print(f"  âš ï¸ ã‚¯ã‚¨ãƒª '{query['query_id']}' æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            colbert_search_times.append(0)
            colbert_search_results.append([])

avg_search_time = np.mean(colbert_search_times) if colbert_search_times else 0
print(f"âœ… ColVBERT éšå±¤çš„æ¤œç´¢å®Œäº†")
print(f"  å¹³å‡æ¤œç´¢æ™‚é–“: {avg_search_time*1000:.2f}ms")

# ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
del colbert_system
torch.cuda.empty_cache()

print("\n" + "=" * 80)
print("ColModernVBERT (SigLIP) ã§RAPTOR Treeæ§‹ç¯‰ + è©•ä¾¡")
print("=" * 80)

# ã‚¹ãƒ†ãƒƒãƒ—7: ColModernVBERT (SigLIP) ã§RAPTOR Treeæ§‹ç¯‰
print(f"\n[ã‚¹ãƒ†ãƒƒãƒ— 7/10] ColModernVBERT (SigLIP) ã§RAPTOR Treeæ§‹ç¯‰ä¸­...")
print(f"  å¯¾è±¡ãƒãƒ£ãƒ³ã‚¯æ•°: {len(visual_documents)}")

modern_config = {
    'encoder_type': 'modern',
    'text_model': 'google/siglip-base-patch16-224',  # SigLIPã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
    'vision_model': 'google/siglip-base-patch16-224',
    'embedding_dim': 768,
    'use_cross_attention': True
}

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆé–‹å§‹å‰ï¼‰
gpu_before_modern = get_gpu_memory_usage()
print(f"GPUçŠ¶æ…‹ (é–‹å§‹å‰): {gpu_before_modern['memory_used_mb']:.0f}MB / {gpu_before_modern['memory_total_mb']:.0f}MB")

modern_system = VisualRAPTORColBERT(
    embeddings_model=embeddings_model,
    llm=llm,
    use_modern_vbert=True,
    colbert_config=modern_config,
    pdf_source_dir=str(pdf_source_dir)
)

print("ColModernVBERTåˆæœŸåŒ–å®Œäº† - RAPTOR Treeæ§‹ç¯‰é–‹å§‹...")

# RAPTOR Treeã‚’æ§‹ç¯‰ã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿
modern_tree = None
modern_tree_build_time = 0
modern_tree_stats = {'num_leaf_nodes': 0, 'num_internal_nodes': 0, 'total_nodes': 0, 'max_depth': 0}
modern_tree_pickle = trees_dir / "colmodern_siglip_tree_46pdfs_chunked.pkl"

if modern_tree_pickle.exists():
    print(f"ğŸ“‚ æ—¢å­˜ã®ColModernVBERT Treeã‚’èª­ã¿è¾¼ã¿ä¸­: {modern_tree_pickle}")
    try:
        import pickle
        with open(modern_tree_pickle, 'rb') as f:
            tree_data = pickle.load(f)
            modern_tree = tree_data['tree']
            modern_tree_build_time = tree_data['build_time']
            modern_tree_stats = tree_data['stats']
        print(f"âœ… ColModernVBERT Treeèª­ã¿è¾¼ã¿å®Œäº†")
        print(f"  æ§‹ç¯‰æ™‚é–“ (å‰å›): {modern_tree_build_time:.2f}ç§’ ({modern_tree_build_time/60:.1f}åˆ†)")
        print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {modern_tree_stats['total_nodes']}")
        print(f"  ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {modern_tree_stats['num_leaf_nodes']}")
        print(f"  å†…éƒ¨ãƒãƒ¼ãƒ‰: {modern_tree_stats['num_internal_nodes']}")
        print(f"  æœ€å¤§æ·±åº¦: {modern_tree_stats['max_depth']}")
        # Treeã‚’ã‚·ã‚¹ãƒ†ãƒ ã«è¨­å®š
        modern_system.tree = modern_tree
    except Exception as e:
        print(f"âš ï¸ Treeèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print("æ–°è¦ã«Treeã‚’æ§‹ç¯‰ã—ã¾ã™...")
        modern_tree = None

if modern_tree is None:
    print("ğŸŒ³ æ–°è¦ã«RAPTOR Treeã‚’æ§‹ç¯‰ä¸­...")
    modern_tree_start_time = time.time()
    modern_gpu_during_tree = []

    try:
        modern_tree = modern_system.build_tree(visual_documents)
        
        # å®šæœŸçš„ã«GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²
        for i in range(5):
            time.sleep(0.5)
            modern_gpu_during_tree.append(get_gpu_memory_usage())
        
        modern_tree_build_time = time.time() - modern_tree_start_time
        
        # ãƒ„ãƒªãƒ¼çµ±è¨ˆã‚’å–å¾—
        modern_tree_stats = count_tree_nodes(modern_tree)
        
        print(f"âœ… ColModernVBERT RAPTOR Treeæ§‹ç¯‰å®Œäº†")
        print(f"  æ§‹ç¯‰æ™‚é–“: {modern_tree_build_time:.2f}ç§’ ({modern_tree_build_time/60:.1f}åˆ†)")
        print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {modern_tree_stats['total_nodes']}")
        print(f"  ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {modern_tree_stats['num_leaf_nodes']}")
        print(f"  å†…éƒ¨ãƒãƒ¼ãƒ‰: {modern_tree_stats['num_internal_nodes']}")
        print(f"  æœ€å¤§æ·±åº¦: {modern_tree_stats['max_depth']}")
        
        # ãƒ„ãƒªãƒ¼ã‚’pickleã¨ã—ã¦ä¿å­˜
        try:
            import pickle
            with open(modern_tree_pickle, 'wb') as f:
                pickle.dump({
                    'tree': modern_tree,
                    'build_time': modern_tree_build_time,
                    'stats': modern_tree_stats
                }, f)
            print(f"  ãƒ„ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {modern_tree_pickle}")
        except Exception as e:
            print(f"  âš ï¸ ãƒ„ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ„ãƒªãƒ¼çµ±è¨ˆã‚’JSONã¨ã—ã¦ä¿å­˜
        try:
            modern_tree_file = trees_dir / "colmodern_siglip_tree_46pdfs_chunked.json"
            with open(modern_tree_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'build_time': modern_tree_build_time,
                    'stats': modern_tree_stats,
                    'num_chunks': len(visual_documents),
                    'num_pages': len(image_files),
                    'chunk_size': CHUNK_SIZE,
                    'chunk_overlap': CHUNK_OVERLAP,
                    'note': 'Tree structure saved (Document objects not serializable)'
                }, f, indent=2, ensure_ascii=False)
            print(f"  ãƒ„ãƒªãƒ¼çµ±è¨ˆä¿å­˜: {modern_tree_file}")
        except Exception as e:
            print(f"  âš ï¸ ãƒ„ãƒªãƒ¼çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
    except Exception as e:
        print(f"âŒ ColModernVBERT RAPTOR Treeæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
else:
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å ´åˆã¯GPUæ¸¬å®šã‚’ã‚¹ã‚­ãƒƒãƒ—
    modern_gpu_during_tree = []

# GPUä½¿ç”¨é‡æ¸¬å®šï¼ˆå®Œäº†å¾Œï¼‰
gpu_after_modern_tree = get_gpu_memory_usage()
modern_tree_gpu_peak = max([g['memory_used_mb'] for g in modern_gpu_during_tree]) if modern_gpu_during_tree else gpu_after_modern_tree['memory_used_mb']

# ã‚¹ãƒ†ãƒƒãƒ—8: ColModernVBERT (SigLIP) ã§éšå±¤çš„æ¤œç´¢è©•ä¾¡
print(f"\n[ã‚¹ãƒ†ãƒƒãƒ— 8/10] ColModernVBERT (SigLIP) ã§éšå±¤çš„æ¤œç´¢è©•ä¾¡ä¸­...")

modern_search_times = []
modern_search_results = []

if modern_tree:
    for query in queries:
        search_start = time.perf_counter()
        try:
            results = modern_system.retrieve(
                query['query'],
                tree_traversal='collapsed',
                top_k=10
            )
            search_time = time.perf_counter() - search_start
            modern_search_times.append(search_time)
            modern_search_results.append(results)
            
            print(f"  ã‚¯ã‚¨ãƒª '{query['query_id']}': {search_time*1000:.2f}ms, {len(results)}ä»¶å–å¾—")
        except Exception as e:
            print(f"  âš ï¸ ã‚¯ã‚¨ãƒª '{query['query_id']}' æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            modern_search_times.append(0)
            modern_search_results.append([])

avg_modern_search_time = np.mean(modern_search_times) if modern_search_times else 0
print(f"âœ… ColModernVBERT éšå±¤çš„æ¤œç´¢å®Œäº†")
print(f"  å¹³å‡æ¤œç´¢æ™‚é–“: {avg_modern_search_time*1000:.2f}ms")

# ã‚¹ãƒ†ãƒƒãƒ—9: æ¯”è¼ƒçµæœã‚’ä¿å­˜
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 9/10] æ¯”è¼ƒçµæœã‚’ä¿å­˜ä¸­...")

comparison_results = {
    'timestamp': datetime.now().isoformat(),
    'num_chunks': len(visual_documents),
    'num_pages': len(image_files),
    'chunk_size': CHUNK_SIZE,
    'chunk_overlap': CHUNK_OVERLAP,
    'avg_chunks_per_page': len(visual_documents) / len(image_files),
    'num_queries': len(queries),
    'pdf_source': str(pdf_source_dir),
    'colbert_blip': {
        'encoder_type': 'ColVBERT (BLIP)',
        'tree_build_time': colbert_tree_build_time,
        'tree_stats': colbert_tree_stats,
        'gpu_peak_memory_tree_mb': colbert_tree_gpu_peak,
        'avg_search_time_ms': float(np.mean(colbert_search_times) * 1000) if colbert_search_times else 0,
        'median_search_time_ms': float(np.median(colbert_search_times) * 1000) if colbert_search_times else 0,
        'tree_file': str(trees_dir / "colbert_blip_tree_46pdfs_chunked.json")
    },
    'colmodern_vbert_siglip': {
        'encoder_type': 'ColModernVBERT (SigLIP)',
        'tree_build_time': modern_tree_build_time,
        'tree_stats': modern_tree_stats,
        'gpu_peak_memory_tree_mb': modern_tree_gpu_peak,
        'avg_search_time_ms': float(np.mean(modern_search_times) * 1000) if modern_search_times else 0,
        'median_search_time_ms': float(np.median(modern_search_times) * 1000) if modern_search_times else 0,
        'tree_file': str(trees_dir / "colmodern_siglip_tree_46pdfs_chunked.json")
    },
    'comparison': {
        'tree_build_speedup': colbert_tree_build_time / modern_tree_build_time if modern_tree_build_time > 0 else 0,
        'search_speedup': avg_search_time / avg_modern_search_time if avg_modern_search_time > 0 else 0,
        'tree_size_difference': modern_tree_stats['total_nodes'] - colbert_tree_stats['total_nodes'],
        'gpu_memory_difference_mb': modern_tree_gpu_peak - colbert_tree_gpu_peak
    }
}

results_file = results_dir / "raptor_comparison_results_46pdfs_chunked.json"
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(comparison_results, f, indent=2, ensure_ascii=False)

print(f"âœ… çµæœã‚’ {results_file} ã«ä¿å­˜")

# ã‚¹ãƒ†ãƒƒãƒ—10: ã‚µãƒãƒªãƒ¼å‡ºåŠ›
print("\n[ã‚¹ãƒ†ãƒƒãƒ— 10/10] ã‚µãƒãƒªãƒ¼å‡ºåŠ›...")

print("\n" + "=" * 80)
print("ğŸ“Š RAPTOR Treeæ§‹ç¯‰ + éšå±¤çš„æ¤œç´¢ æ€§èƒ½æ¯”è¼ƒã‚µãƒãƒªãƒ¼ï¼ˆ46 PDFã€ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ç‰ˆï¼‰")
print("=" * 80)

print(f"\nã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‘")
print(f"ãƒšãƒ¼ã‚¸æ•°: {len(image_files)}")
print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {len(visual_documents)}")
print(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {CHUNK_SIZE}ãƒˆãƒ¼ã‚¯ãƒ³")
print(f"å¹³å‡ãƒãƒ£ãƒ³ã‚¯æ•°/ãƒšãƒ¼ã‚¸: {len(visual_documents)/len(image_files):.1f}")

print(f"\nã€RAPTOR Treeæ§‹ç¯‰ã€‘")
print(f"ColVBERT (BLIP):")
print(f"  - æ§‹ç¯‰æ™‚é–“: {colbert_tree_build_time:.2f}ç§’ ({colbert_tree_build_time/60:.1f}åˆ†)")
print(f"  - ç·ãƒãƒ¼ãƒ‰æ•°: {colbert_tree_stats['total_nodes']}")
print(f"  - ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {colbert_tree_stats['num_leaf_nodes']}")
print(f"  - å†…éƒ¨ãƒãƒ¼ãƒ‰: {colbert_tree_stats['num_internal_nodes']}")
print(f"  - æœ€å¤§æ·±åº¦: {colbert_tree_stats['max_depth']}")

print(f"\nColModernVBERT (SigLIP):")
print(f"  - æ§‹ç¯‰æ™‚é–“: {modern_tree_build_time:.2f}ç§’ ({modern_tree_build_time/60:.1f}åˆ†)")
print(f"  - ç·ãƒãƒ¼ãƒ‰æ•°: {modern_tree_stats['total_nodes']}")
print(f"  - ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {modern_tree_stats['num_leaf_nodes']}")
print(f"  - å†…éƒ¨ãƒãƒ¼ãƒ‰: {modern_tree_stats['num_internal_nodes']}")
print(f"  - æœ€å¤§æ·±åº¦: {modern_tree_stats['max_depth']}")

if modern_tree_build_time > 0:
    speedup = colbert_tree_build_time / modern_tree_build_time
    time_saved = colbert_tree_build_time - modern_tree_build_time
    print(f"\nâš¡ Treeæ§‹ç¯‰é«˜é€ŸåŒ–ç‡: {speedup:.2f}x")
    print(f"âš¡ æ™‚é–“çŸ­ç¸®: {time_saved:.1f}ç§’ ({time_saved/60:.1f}åˆ†)")

print(f"\nã€éšå±¤çš„æ¤œç´¢æ€§èƒ½ã€‘")
if colbert_search_times:
    print(f"ColVBERT (BLIP):")
    print(f"  - å¹³å‡æ¤œç´¢æ™‚é–“: {np.mean(colbert_search_times)*1000:.2f}ms")
    print(f"  - ä¸­å¤®å€¤: {np.median(colbert_search_times)*1000:.2f}ms")

if modern_search_times:
    print(f"\nColModernVBERT (SigLIP):")
    print(f"  - å¹³å‡æ¤œç´¢æ™‚é–“: {np.mean(modern_search_times)*1000:.2f}ms")
    print(f"  - ä¸­å¤®å€¤: {np.median(modern_search_times)*1000:.2f}ms")

print(f"\nã€GPUä½¿ç”¨é‡ã€‘")
print(f"ColVBERT (BLIP) ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {colbert_tree_gpu_peak:.0f}MB")
print(f"ColModernVBERT (SigLIP) ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {modern_tree_gpu_peak:.0f}MB")
if modern_tree_gpu_peak > 0:
    gpu_diff = modern_tree_gpu_peak - colbert_tree_gpu_peak
    gpu_diff_percent = (gpu_diff / colbert_tree_gpu_peak) * 100 if colbert_tree_gpu_peak > 0 else 0
    print(f"å·®åˆ†: {gpu_diff:.0f}MB ({gpu_diff_percent:+.1f}%)")

print("\n" + "=" * 80)
print("âœ… RAPTOR Treeæ§‹ç¯‰ + éšå±¤çš„æ¤œç´¢ æ€§èƒ½æ¯”è¼ƒå®Œäº†ï¼ˆãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ç‰ˆï¼‰!")
print(f"ğŸ“ çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {results_dir}")
print(f"ğŸ“„ è©³ç´°çµæœ: {results_file}")
print(f"ğŸŒ³ RAPTORãƒ„ãƒªãƒ¼: {trees_dir}")
print("=" * 80)
