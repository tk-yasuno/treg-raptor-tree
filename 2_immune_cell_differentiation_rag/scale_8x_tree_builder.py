"""
8x Scale Parallel Processing with Tree Construction and Visualization
8å€ã‚¹ã‚±ãƒ¼ãƒ«ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹ãƒ„ãƒªãƒ¼æ§‹ç¯‰ã¨å¯è¦–åŒ–

Author: AI Assistant
Date: 2025-10-31
"""

import sys
import time
import json
import multiprocessing as mp
from pathlib import Path
from datetime import datetime
import logging

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from immune_raptor_tree import ImmuneCellRAPTORTree
from rate_limited_parallel import optimize_immune_raptor_parallel


class Scale8xTreeBuilder:
    """8å€ã‚¹ã‚±ãƒ¼ãƒ«ç”¨ãƒ„ãƒªãƒ¼æ§‹ç¯‰ãƒ»å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.base_dir = Path("C:/Users/yasun/LangChain/learning-langchain/treg-raptor-tree")
        self.cache_dir = self.base_dir / "data/immune_cell_differentiation"
        self.results_dir = self.cache_dir / "scaling_results"
        self.results_dir.mkdir(exist_ok=True)
        
        # 8å€ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š
        self.scale = "8x"
        self.articles_per_query = 160  # 8å€ã‚¹ã‚±ãƒ¼ãƒ«
        self.workers = 4
        
        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()
        
    def setup_logging(self):
        """ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = self.results_dir / f"scale_8x_tree_build_{timestamp}.log"
        
        # ãƒ­ã‚¬ãƒ¼è¨­å®š
        self.logger = logging.getLogger('Scale8xTreeBuilder')
        self.logger.setLevel(logging.INFO)
        
        # æ—¢å­˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        self.logger.handlers.clear()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¿½åŠ 
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        self.logger.info(f"8x Scale Tree Builder Log initialized: {self.log_file}")
        
    def log_info(self, message: str):
        """æƒ…å ±ãƒ­ã‚°"""
        self.logger.info(message)
        
    def log_error(self, message: str):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"""
        self.logger.error(message)
        
    def build_8x_scale_tree(self):
        """8å€ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ãƒ„ãƒªãƒ¼æ§‹ç¯‰å®Ÿè¡Œ"""
        
        self.log_info("ğŸš€ 8X SCALE PARALLEL TREE CONSTRUCTION STARTED")
        self.log_info("=" * 70)
        self.log_info(f"Scale: {self.scale}")
        self.log_info(f"Articles per query: {self.articles_per_query}")
        self.log_info(f"CPU cores available: {mp.cpu_count()}")
        self.log_info(f"Workers to use: {self.workers}")
        
        total_start = time.time()
        
        try:
            # Phase 1: ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            self.log_info("\\nğŸ§¬ Phase 1: System Initialization")
            
            raptor_tree = ImmuneCellRAPTORTree(str(self.cache_dir))
            
            # å…ç–«ç´°èƒéšå±¤ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            immune_file = self.cache_dir / "immune_cell_hierarchy.json"
            if not immune_file.exists():
                self.log_error(f"Required file not found: {immune_file}")
                return False
                
            raptor_tree.load_immune_hierarchy(str(immune_file))
            self.log_info(f"âœ“ Loaded {len(raptor_tree.nodes)} immune cell nodes")
            
            # Phase 2: FAISS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            self.log_info("\\nâš¡ Phase 2: FAISS Index Construction")
            index_start = time.time()
            
            raptor_tree.build_faiss_index_parallel(workers=self.workers)
            
            index_time = time.time() - index_start
            self.log_info(f"âœ“ FAISS index built in {index_time:.1f}s")
            
            # Phase 3: 8å€ã‚¹ã‚±ãƒ¼ãƒ«PubMedçµ±åˆ
            self.log_info(f"\\nğŸ“¡ Phase 3: 8x Scale PubMed Integration ({self.articles_per_query} articles/query)")
            integration_start = time.time()
            
            parallel_metrics = optimize_immune_raptor_parallel(
                raptor_tree,
                max_articles_per_query=self.articles_per_query,
                max_workers=self.workers
            )
            
            integration_time = time.time() - integration_start
            total_articles = len(raptor_tree.pubmed_articles)
            
            self.log_info(f"âœ“ 8x Scale PubMed integration completed")
            self.log_info(f"   Total articles: {total_articles}")
            self.log_info(f"   Integration time: {integration_time:.1f}s")
            self.log_info(f"   Processing rate: {total_articles / integration_time:.1f} articles/second")
            
            if parallel_metrics:
                self.log_info(f"   Parallel metrics:")
                self.log_info(f"     Retrieval time: {parallel_metrics.get('retrieval_time', 0):.1f}s")
                self.log_info(f"     Encoding time: {parallel_metrics.get('encoding_time', 0):.1f}s")
                self.log_info(f"     Workers used: {parallel_metrics.get('workers_used', 4)}")
                self.log_info(f"     Parallel efficiency: {parallel_metrics.get('parallel_efficiency', 0):.0f}%")
            
            # Phase 4: ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
            self.log_info("\\nğŸ” Phase 4: System Testing")
            search_start = time.time()
            
            test_queries = [
                "FOXP3+ regulatory T cell differentiation",
                "Treg immune suppression mechanisms", 
                "thymic versus peripheral Treg development",
                "IL-10 production by regulatory T cells",
                "CTLA-4 checkpoint inhibition mechanism"
            ]
            
            search_results = []
            for i, query in enumerate(test_queries, 1):
                try:
                    results = raptor_tree.hierarchical_search(query, top_k=5)
                    search_results.append(len(results))
                    self.log_info(f"   Test {i}: '{query[:50]}...' â†’ {len(results)} results")
                    
                    # ãƒˆãƒƒãƒ—çµæœã®è©³ç´°ãƒ­ã‚°
                    if results:
                        top_node_id, top_score = results[0]
                        top_node = raptor_tree.nodes[top_node_id]
                        self.log_info(f"     Top result: {top_node.cell_type} ({top_node.subtype}) - Score: {top_score:.3f}")
                        
                except Exception as e:
                    self.log_error(f"   Test {i} failed: {e}")
                    search_results.append(0)
            
            search_time = time.time() - search_start
            
            # Phase 5: ãƒ„ãƒªãƒ¼å¯è¦–åŒ–
            self.log_info("\\nğŸ–¼ï¸  Phase 5: Tree Visualization")
            viz_start = time.time()
            
            # 8å€ã‚¹ã‚±ãƒ¼ãƒ«ç”¨å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«
            output_dir = self.cache_dir / "raptor_trees"
            output_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            try:
                # éšå±¤å¯è¦–åŒ–
                viz_file = output_dir / f"immune_hierarchy_8x_scale_{timestamp}.png"
                raptor_tree.visualize_hierarchy(str(viz_file))
                self.log_info(f"âœ“ Hierarchy visualization saved: {viz_file.name}")
                
                # åˆ†åŒ–çµŒè·¯å¯è¦–åŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                try:
                    path = raptor_tree.trace_differentiation_path("HSC", "Treg")
                    if path:
                        self.log_info(f"âœ“ Differentiation path traced: {' â†’ '.join(path.pathway_nodes)}")
                        self.log_info(f"   Key factors: {', '.join(path.key_factors[:5])}")
                    else:
                        self.log_info("â„¹ï¸  No differentiation path found")
                except Exception as e:
                    self.log_info(f"â„¹ï¸  Differentiation path tracing not available: {e}")
                
            except Exception as e:
                self.log_error(f"Visualization error: {e}")
            
            viz_time = time.time() - viz_start
            
            # Phase 6: 8å€ã‚¹ã‚±ãƒ¼ãƒ«ãƒ„ãƒªãƒ¼ä¿å­˜
            self.log_info("\\nğŸ’¾ Phase 6: 8x Scale Tree Saving")
            save_start = time.time()
            
            try:
                # RAPTOR Treeä¿å­˜
                tree_file = output_dir / f"immune_cell_raptor_tree_8x_scale_{timestamp}.json"
                raptor_tree.save_raptor_tree(str(tree_file))
                self.log_info(f"âœ“ 8x Scale Tree saved: {tree_file.name}")
                
                # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜
                embeddings_file = output_dir / f"immune_cell_raptor_tree_embeddings_8x_{timestamp}.pkl"
                embeddings_data = {
                    'node_embeddings': {node_id: node.embedding for node_id, node in raptor_tree.nodes.items() if node.embedding is not None},
                    'article_embeddings': raptor_tree.article_embeddings
                }
                
                import pickle
                with open(embeddings_file, 'wb') as f:
                    pickle.dump(embeddings_data, f)
                self.log_info(f"âœ“ 8x Scale Embeddings saved: {embeddings_file.name}")
                
                # FAISS ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜
                if raptor_tree.faiss_index is not None:
                    import faiss
                    faiss_file = output_dir / f"immune_cell_raptor_tree_faiss_8x_{timestamp}.index"
                    faiss.write_index(raptor_tree.faiss_index, str(faiss_file))
                    self.log_info(f"âœ“ 8x Scale FAISS index saved: {faiss_file.name}")
                
            except Exception as e:
                self.log_error(f"Saving error: {e}")
            
            save_time = time.time() - save_start
            total_time = time.time() - total_start
            
            # çµæœã¾ã¨ã‚
            result = {
                'scale': self.scale,
                'articles_per_query': self.articles_per_query,
                'total_articles': total_articles,
                'total_time': total_time,
                'index_time': index_time,
                'integration_time': integration_time,
                'search_time': search_time,
                'visualization_time': viz_time,
                'save_time': save_time,
                'articles_per_second': total_articles / integration_time if integration_time > 0 else 0,
                'search_results_count': sum(search_results),
                'parallel_metrics': parallel_metrics,
                'timestamp': datetime.now().isoformat(),
                'status': 'SUCCESS',
                'output_files': {
                    'visualization': viz_file.name if 'viz_file' in locals() else None,
                    'tree_json': tree_file.name if 'tree_file' in locals() else None,
                    'embeddings': embeddings_file.name if 'embeddings_file' in locals() else None,
                    'faiss_index': faiss_file.name if 'faiss_file' in locals() else None
                }
            }
            
            # çµæœä¿å­˜
            result_file = self.results_dir / f"scale_8x_result_{timestamp}.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            
            # æˆåŠŸãƒ­ã‚°
            self.log_info("\\nâœ… 8X SCALE TREE CONSTRUCTION COMPLETED SUCCESSFULLY")
            self.log_info("=" * 70)
            self.log_info(f"ğŸ“Š Final Results Summary:")
            self.log_info(f"   Scale: {self.scale}")
            self.log_info(f"   Total execution time: {total_time:.1f}s")
            self.log_info(f"   Articles processed: {total_articles}")
            self.log_info(f"   Processing rate: {result['articles_per_second']:.1f} articles/second")
            self.log_info(f"   Search tests passed: {sum(search_results)}/{len(test_queries)}")
            self.log_info(f"   Visualization time: {viz_time:.1f}s")
            self.log_info(f"   Save time: {save_time:.1f}s")
            self.log_info(f"\\nğŸ“ Output Files:")
            for file_type, filename in result['output_files'].items():
                if filename:
                    self.log_info(f"   {file_type}: {filename}")
            self.log_info(f"\\nğŸ“ Complete log: {self.log_file.name}")
            self.log_info(f"ğŸ“Š Result data: {result_file.name}")
            
            return True
            
        except Exception as e:
            error_time = time.time() - total_start
            self.log_error(f"âŒ 8X SCALE TREE CONSTRUCTION FAILED: {str(e)}")
            self.log_error(f"   Execution time before failure: {error_time:.1f}s")
            
            # ã‚¨ãƒ©ãƒ¼çµæœä¿å­˜
            error_result = {
                'scale': self.scale,
                'articles_per_query': self.articles_per_query,
                'error': str(e),
                'execution_time': error_time,
                'timestamp': datetime.now().isoformat(),
                'status': 'FAILED'
            }
            
            error_file = self.results_dir / f"scale_8x_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(error_file, 'w', encoding='utf-8') as f:
                json.dump(error_result, f, indent=2, ensure_ascii=False)
            
            self.log_error(f"   Error details saved: {error_file.name}")
            
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("ğŸš€ 8X SCALE PARALLEL TREE CONSTRUCTION & VISUALIZATION")
    print("=" * 70)
    
    # 8å€ã‚¹ã‚±ãƒ¼ãƒ«ãƒ„ãƒªãƒ¼ãƒ“ãƒ«ãƒ€ãƒ¼åˆæœŸåŒ–
    builder = Scale8xTreeBuilder()
    
    try:
        success = builder.build_8x_scale_tree()
        
        if success:
            print(f"\\nâœ… 8x Scale Tree Construction completed successfully!")
            print(f"ğŸ“ Detailed log: {builder.log_file}")
            print(f"ğŸ“ Output files saved in: {builder.cache_dir}/raptor_trees/")
            print(f"ğŸ“Š Results saved in: {builder.results_dir}")
        else:
            print(f"\\nâŒ 8x Scale Tree Construction failed.")
            print(f"ğŸ“ Check log file: {builder.log_file}")
            
    except KeyboardInterrupt:
        print("\\nâš ï¸  Construction interrupted by user")
    except Exception as e:
        print(f"\\nâŒ Critical error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()